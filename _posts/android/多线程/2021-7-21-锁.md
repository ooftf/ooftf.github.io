---
published: false
---

##  synchronized
synchronized关键字，这是一种块结构（Block Structured）的同步语法。synchronized关键字经过Javac编译之后，会在同步块的前后分别形成
monitorenter和monitorexit这两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明
要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作
为reference；如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来
决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁。

在执行monitorenter指令时，首先要去尝试获取对象的锁。如果
这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行
monitorexit指令时会将锁计数器的值减一。一旦计数器的值为零，锁随即就被释放了。如果获取对象
锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止

* 被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块
也不会出现自己把自己锁死的情况。
* 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他
线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制
正在等待锁的线程中断等待或超时退出。

从执行成本的角度看，持有锁是一个重量级（Heavy-Weight）的操作。在第10章中我们知道了在
主流Java虚拟机实现中，Java的线程是映射到操作系统的原生内核线程之上的，如果要阻塞或唤醒一条
线程，则需要操作系统来帮忙完成，这就不可避免地陷入用户态到核心态的转换中，进行这种状态转
换需要耗费很多的处理器时间。

## Lock
JDK 5，Java 类库中新提供了java.util.concurrent包（下文称J.U.C包），其中的
java.util.concurrent.locks.Lock接口便成了Java的另一种全新的互斥同步手段。基于 Lock 接口，用户能够
以非块结构（Non-Block Structured）来实现互斥同步，从而摆脱了语言特性的束缚，改为在类库层面
去实现同步，这也为日后扩展出不同调度算法、不同特征、不同性能、不同语义的各种锁提供了广阔
的空间

### ReentrantLock

#### 功能差异
ReentrantLock与synchronized相比增加了一些高级功能，主要有以下三项：

1. 等待可中断：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改
为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。
2. 公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平
锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非
公平的，ReentrantLock在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平
锁。不过一旦使用了公平锁，将会导致ReentrantLock的性能急剧下降，会明显影响吞吐量。
3. 锁绑定多个条件：是指一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized
中，锁对象的wait()跟它的notify()或者notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一
个的条件关联的时候，就不得不额外添加一个锁；而ReentrantLock则无须这样做，多次调用
newCondition()方法即可。

#### 性能差异
JDK 6或以上版 synchronized 和 ReentrantLock 性能几乎相同
ReentrantLock 在功能上是 synchronized 的超集，但是 synchronized是在Java语法层面的同步，足够清晰，也足够简单。
推荐在synchronized与ReentrantLock都可满足需要时优先使用synchronized

#### 使用体验差异
Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不
会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确
保即使出现异常，锁也能被自动释放

# 阻塞式同步
Java的线程是映射到操作系统的原生内核线程之上的，如果要阻塞或唤醒一条
线程，则需要操作系统来帮忙完成，这就不可避免地陷入用户态到核心态的转换中，进行这种状态转
换需要耗费很多的处理器时间。
# 非阻塞同步

互斥同步面临的主要问题是进行线程阻塞和唤醒所带来的性能开销，因此这种同步也被称为阻塞
同步（Blocking Synchronization）。从解决问题的方式上看，互斥同步属于一种悲观的并发策略，其总
是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享的数据是否真的会
出现竞争，它都会进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加
锁），这将会导致用户态到核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等开
销。随着硬件指令集的发展，我们已经有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说
就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数
据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现
没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被
称为非阻塞同步（Non-Blocking Synchronization），使用这种措施的代码也常被称为无锁（Lock-Free）
编程。

为什么笔者说使用乐观并发策略需要“硬件指令集的发展”？因为我们必须要求操作和冲突检测这
两个步骤具备原子性。靠什么来保证原子性？如果这里再使用互斥同步来保证就完全失去意义了，所
以我们只能靠硬件来实现这件事情，硬件保证某些从语义上看起来需要多次操作的行为可以只通过一
条处理器指令就能完成


## 自旋锁与自适应自旋
### 什么是自旋锁
前面我们讨论互斥同步的时候，提到了互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢
复线程的操作都需要转入内核态中完成，这些操作给Java虚拟机的并发性能带来了很大的压力。同
时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了
这段时间去挂起和恢复线程并不值得。现在绝大多数的个人电脑和服务器都是多路（核）处理器系
统，如果物理机器有一个以上的处理器或者处理器核心，能让两个或以上的线程同时并行执行，我们
就可以让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很
快就会释放锁。为了让线程等待，我们只须让线程执行一个忙循环（自旋），这项技术就是所谓的自
旋锁。
### 自旋锁的确定
自旋锁在JDK 1.4.2中就已经引入，只不过默认是关闭的，可以使用-XX：+UseSpinning参数来开
启，在JDK 6中就已经改为默认开启了。自旋等待不能代替阻塞，且先不说对处理器数量的要求，自
旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，所以如果锁被占用的时间很
短，自旋等待的效果就会非常好，反之如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理
器资源，而不会做任何有价值的工作，这就会带来性能的浪费。因此自旋等待的时间必须有一定的限
度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程。自旋次数
的默认值是十次，用户也可以使用参数-XX：PreBlockSpin来自行更改。
### 什么是自适应自旋
不过无论是默认值还是用户指定的自旋次数，对整个Java虚拟机中所有的锁来说都是相同的。在
JDK 6中对自旋锁的优化，引入了自适应的自旋。自适应意味着自旋的时间不再是固定的了，而是由
前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚
刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成
功，进而允许自旋等待持续相对更长的时间，比如持续100次忙循环。另一方面，如果对于某个锁，自
旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资
源。有了自适应自旋，随着程序运行时间的增长及性能监控信息的不断完善，虚拟机对程序锁的状况
预测就会越来越精准，虚拟机就会变得越来越“聪明”了。


## 锁消除
锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享
数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸
分析技术），如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可
以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行。
也许读者会有疑问，变量是否逃逸，对于虚拟机来说是需要使用复杂的过程间分析才能确定的，
但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下还要求同步呢？这个问题
的答案是：有许多同步措施并不是程序员自己加入的，同步的代码在Java程序中出现的频繁程度也许
超过了大部分读者的想象。我们来看看如代码清单13-6所示的例子，这段非常简单的代码仅仅是输出
三个字符串相加的结果，无论是源代码字面上，还是程序语义上都没有进行同步。
一段看起来没有同步的代码

```java
public String concatString(String s1, String s2, String s3) {
 return s1 + s2 + s3;
}
```

我们也知道，由于String是一个不可变的类，对字符串的连接操作总是通过生成新的String对象来
进行的，因此Javac编译器会对String连接做自动优化。在JDK 5之前，字符串加法会转化为StringBuffer
对象的连续append()操作，在JDK 5及以后的版本中，会转化为StringBuilder对象的连续append()操作。
即代码清单13-6所示的代码可能会变成代码清单13-7所示的样子[1]。
代码清单13-7 Javac转化后的字符串连接操作

```java
public String concatString(String s1, String s2, String s3) {
 StringBuffer sb = new StringBuffer();
 sb.append(s1);
 sb.append(s2);
 sb.append(s3);
 return sb.toString();
}
```

现在大家还认为这段代码没有涉及同步吗？每个StringBuffer.append()方法中都有一个同步块，锁
就是sb对象。虚拟机观察变量sb，经过逃逸分析后会发现它的动态作用域被限制在concatString()方法内
部。也就是sb的所有引用都永远不会逃逸到concatString()方法之外，其他线程无法访问到它，所以这里
虽然有锁，但是可以被安全地消除掉。在解释执行时这里仍然会加锁，但在经过服务端编译器的即时
编译之后，这段代码就会忽略所有的同步措施而直接执行。
[1] 客观地说，既然谈到锁消除与逃逸分析，那虚拟机就不可能是JDK 5之前的版本，所以实际上会转
化为非线程安全的StringBuilder来完成字符串拼接，并不会加锁。但是这也不影响笔者用这个例子证明
Java对象中同步的普遍性。

## 锁粗化

原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据
的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等
待锁的线程也能尽可能快地拿到锁。
大多数情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和
解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导
致不必要的性能损耗。
代码清单13-7所示连续的append()方法就属于这类情况。如果虚拟机探测到有这样一串零碎的操作
都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部，以代码清单13-7
为例，就是扩展到第一个append()操作之前直至最后一个append()操作之后，这样只需要加锁一次就可
以了。

```java
val sb = StringBuffer();
sb.append("1")
sb.append("1")
sb.append("1")
sb.append("1")
```
粗化之后，appen 内部不再有锁，而是在外层加一次锁
```java
val sb = StringBuilder();
synchronized(sb){
    sb.append("1")
    sb.append("1")
    sb.append("1")
    sb.append("1")
}

```

## 　轻量级锁